{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cloudpathlib[azure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b9aeb533-b46f-4495-9a4d-bbfc66ae2a46",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "import warnings\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import SparkSession\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient\n",
    "from io import StringIO\n",
    "from cloudpathlib import CloudPath, AzureBlobClient\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e6e462a5-7bb0-440f-a23d-2abd39a4a589",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "azure_conn_string = \"somevalue\"\n",
    "azure_key = \"somevalue\"\n",
    "azure_storage = \"somevalue\"\n",
    "azure_url = \"somevalue\"\n",
    "azure_container = \"somevalue\"\n",
    "\n",
    "# Temporary\n",
    "tmp_county_path = 'tmp/initial/county'\n",
    "tmp_stock_path = 'tmp/initial/financial/stocks'\n",
    "tmp_indicator_path = 'tmp/initial/financial/indicators'\n",
    "\n",
    "# Permanent\n",
    "county_path = 'data/initial/county'\n",
    "stock_path = 'data/initial/financial/stocks'\n",
    "indicator_path = 'data/initial/financial/indicators'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "989c49b4-880e-4b82-a25a-2d4e42bb4153",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set Azure blob configuration\n",
    "spark.conf.set(f\"fs.azure.account.key.{azure_storage}.blob.core.windows.net\", azure_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fea33c86-ab03-4849-ba6c-40b3637ebdc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CleanAndStore:\n",
    "\n",
    "    def __init__(self, load, load_type, save_path):\n",
    "        self.df = self.load_file(load, load_type)\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def load_file(self, load, load_type):\n",
    "        \"\"\"\n",
    "        Load file from tmp storage\n",
    "        \"\"\"\n",
    "        if load_type == 'csv':\n",
    "            self.df = spark.read.format(load_type).option(\"header\", True).load(f\"wasbs://{azure_container}@{azure_storage}.blob.core.windows.net/{load}\")\n",
    "\n",
    "            return self.df\n",
    "          \n",
    "        elif load_type == 'json':\n",
    "            self.df = spark.read.format(load_type).option(\"header\", True).load(f\"wasbs://{azure_container}@{azure_storage}.blob.core.windows.net/{load}\")\n",
    "\n",
    "            return self.df\n",
    "          \n",
    "    def load_excel(self, load, rows, columns=None):\n",
    "    \n",
    "        blob_service_client = BlobServiceClient(account_url=azure_url, credential=azure_key)\n",
    "\n",
    "        blob_client = blob_service_client.get_blob_client(container=azure_container, blob=load)\n",
    "        downloader = blob_client.download_blob()\n",
    "        \n",
    "        if columns:\n",
    "            self.df = pd.read_excel(downloader.readall(), engine='openpyxl', names=columns, skiprows=rows)\n",
    "            \n",
    "            return self.df\n",
    "        else:\n",
    "            df = pd.read_excel(downloader.readall(), engine='openpyxl', skiprows=rows)\n",
    "            \n",
    "            return df\n",
    "    \n",
    "    def save_file(self, option, name):\n",
    "        self.df.write.parquet(f'wasbs://{azure_container}@{azure_storage}.blob.core.windows.net/{self.save_path}/{option}/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "19288767-04e0-4b57-b43e-1d2d5e592df4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Florida(CleanAndStore):\n",
    "\n",
    "    def __init__(self, load, load_type, save_path):\n",
    "        super().__init__(load, load_type, save_path)\n",
    "        self.year = load[-9:-5]\n",
    "        self.wrangle()\n",
    "\n",
    "    def wrangle(self):\n",
    "\n",
    "        self.df = self.df.select(col(\"Age\").cast(\"int\").alias(\"age\"),\n",
    "                                when(col(\"Case_\") == \"Yes\", 1).alias(\"case\"),\n",
    "                                upper(col(\"Contact\")).alias(\"contact\"),\n",
    "                                upper(col(\"County\")).alias(\"county\"),\n",
    "                                upper(col(\"Died\")).alias(\"died\"),\n",
    "                                upper(col(\"EDvisit\")).alias(\"ed_visit\"),\n",
    "                                to_date(to_timestamp(from_unixtime(substring(col(\"EventDate\").cast(\"string\"), 1, 10)))).alias(\"date\"),\n",
    "                                upper(col(\"Gender\")).alias(\"gender\"),\n",
    "                                upper(col(\"Origin\")).alias(\"origin\")).distinct().orderBy(\"date\")\n",
    "\n",
    "        self.df = self.df.withColumn(\"state\", lit(\"FL\"))\n",
    "\n",
    "        self.df = self.df.filter(self.df.county != \"UNKNOWN\")\n",
    "\n",
    "        # Write preprocessed\n",
    "        super().save_file('preprocessed', f'florida{self.year}')\n",
    "\n",
    "        self.df = self.df.select(\"date\", \"county\", \"state\", \"case\").groupBy(\"date\", \"county\", \"state\").agg(count(\"case\").cast(\"int\").alias(\"new_cases\")).orderBy(\"date\", \"county\")\n",
    "\n",
    "        # Write final\n",
    "        super().save_file('final', f'florida{self.year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "27b410c4-b458-4a76-80d9-509f7cc6a536",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Texas(CleanAndStore):\n",
    "\n",
    "    def __init__(self, load, save_path):\n",
    "        self.save_path = save_path\n",
    "        self.columns = []\n",
    "        self.set_column_names(load)\n",
    "        super().load_excel(load, 2, self.columns)\n",
    "        self.wrangle()\n",
    "\n",
    "    def set_column_names(self, load):\n",
    "        \"\"\"\n",
    "        Transform column names so that the names can be referenced in each row\n",
    "        \"\"\"\n",
    "\n",
    "        df_columns = super().load_excel(load, 2)\n",
    "\n",
    "        self.columns = []\n",
    "        self.columns.append('County Name')\n",
    "\n",
    "        for column in df_columns.columns[1:]:\n",
    "            self.columns.append(datetime.strptime(column.replace('Cases', ' ').lstrip(), '%m-%d-%Y'))\n",
    "\n",
    "    def wrangle(self):\n",
    "        \"\"\"\n",
    "        Convert data frame sourced from Excel into JSON format\n",
    "        \"\"\"\n",
    "\n",
    "        drop_rows = self.df.iloc[254:]\n",
    "\n",
    "        self.df = self.df.drop(drop_rows.index, axis=0)\n",
    "\n",
    "        counties = self.df['County Name'].tolist()\n",
    "\n",
    "        records = []\n",
    "\n",
    "        for county in counties:\n",
    "            for date in self.columns[1:]:\n",
    "                records.append([date, county])\n",
    "\n",
    "        county_cases = []\n",
    "\n",
    "        for row in self.df.itertuples(index=True):\n",
    "            county_cases.append(row[2:])\n",
    "\n",
    "        case_count = []\n",
    "\n",
    "        for county in county_cases:\n",
    "            for cases in county:\n",
    "                case_count.append(cases)\n",
    "\n",
    "        for i in range(len(records)):\n",
    "            records[i].append(case_count[i])\n",
    "\n",
    "        final_list = []\n",
    "\n",
    "        for row in records:\n",
    "            final_dict = {}\n",
    "            final_dict['date'] = row[0]\n",
    "            final_dict['county'] = row[1]\n",
    "            final_dict['case_total'] = row[2]\n",
    "            final_list.append(final_dict)\n",
    "\n",
    "        self.df = pd.DataFrame(final_list)\n",
    "\n",
    "        self.df = spark.createDataFrame(self.df)\n",
    "\n",
    "        self.df = self.df.select(to_date(\"date\").alias(\"date\"), \n",
    "                                upper(col(\"county\")).alias(\"county\"), \n",
    "                                col(\"case_total\").cast(\"int\")).distinct()\n",
    "\n",
    "        self.df = self.df.withColumn(\"state\", lit(\"TX\"))\n",
    "\n",
    "        self.df = self.df.filter(self.df.county != \"UNKNOWN\")\n",
    "\n",
    "        windowSpec = Window.partitionBy(\"county\").orderBy(\"date\")\n",
    "\n",
    "        self.df = self.df.withColumn(\"previous_day\", lag(\"case_total\", 1).over(windowSpec))\n",
    "\n",
    "        self.df = self.df.withColumn(\"new_cases\", (self.df.case_total - self.df.previous_day))\n",
    "\n",
    "        # Write preprocessed\n",
    "        super().save_file('preprocessed', 'texas')\n",
    "\n",
    "        self.df = self.df.select(\"date\", \"county\", \"state\", \"new_cases\")\n",
    "\n",
    "        # Write final\n",
    "        super().save_file('final', 'texas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a7934093-4cfc-40a7-b81e-98564594fb99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NewYork(CleanAndStore):\n",
    "    \n",
    "    def __init__(self, load, load_type, save_path):\n",
    "        super().__init__(load, load_type, save_path)\n",
    "        self.wrangle()\n",
    "\n",
    "    def wrangle(self):\n",
    "\n",
    "        self.df = self.df.select(upper(col(\"county\")).alias(\"county\"), \n",
    "                                col(\"cumulative_number_of_positives\").cast(\"int\").alias(\"total_cases\"),\n",
    "                                col(\"cumulative_number_of_tests\").cast(\"int\").alias(\"total_tests\"),\n",
    "                                col(\"new_positives\").cast(\"int\").alias(\"new_cases\"),\n",
    "                                to_date(to_timestamp(col(\"test_date\"))).alias(\"date\"),\n",
    "                                col(\"total_number_of_tests\").cast(\"int\").alias(\"new_tests\")).distinct().orderBy(\"test_date\")\n",
    "\n",
    "        self.df = self.df.withColumn(\"state\", lit(\"NY\"))\n",
    "\n",
    "        self.df = self.df.filter(\"county != 'UNKNOWN'\")\n",
    "\n",
    "        # Write preprocessed\n",
    "        super().save_file('preprocessed', 'new-york')\n",
    "\n",
    "        self.df = self.df.select(\"date\", \"county\", \"state\", \"new_cases\").orderBy(\"date\", \"county\")\n",
    "\n",
    "        # Write final\n",
    "        super().save_file('final', 'new-york')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "89ae85cb-c54d-4feb-bfdd-1badac26d1bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Pennsylvania(CleanAndStore):\n",
    "\n",
    "    def __init__(self, load, load_type, save_path):\n",
    "        super().__init__(load, load_type, save_path)\n",
    "        self.wrangle()\n",
    "\n",
    "    def wrangle(self):\n",
    "\n",
    "        self.df = self.df.drop('georeferenced_lat__long', ':@computed_region_nmsq_hqvv', ':@computed_region_d3gw_znnf', ':@computed_region_amqz_jbr4', ':@computed_region_r6rf_p9et', ':@computed_region_rayf_jjgk')\n",
    "\n",
    "        self.df = self.df.select(col(\"cases\").cast(\"int\").alias(\"new_cases\"), \n",
    "                     col(\"cases_avg_new\").cast(\"float\").alias(\"cases_avg_new\"), \n",
    "                     col(\"cases_avg_new_rate\").cast(\"float\").alias(\"cases_avg_new_rate\"), \n",
    "                     col(\"cases_cume\").cast(\"int\").alias(\"cases_total\"),\n",
    "                     col(\"cases_cume_rate\").cast(\"float\").alias(\"cases_total_rate\"), \n",
    "                     upper(col(\"county\")).alias(\"county\"), \n",
    "                     col(\"latitude\").cast(\"float\").alias(\"latitude\"), \n",
    "                     col(\"longitude\").cast(\"float\").alias(\"longitude\"), \n",
    "                     col(\"population\").cast(\"int\").alias(\"population\"), \n",
    "                     to_date(to_timestamp(col(\"date\"))).alias(\"date\")).distinct()\n",
    "\n",
    "        self.df = self.df.withColumn(\"state\", lit(\"PA\"))\n",
    "\n",
    "        self.df = self.df.filter(self.df.county != \"UNKNOWN\")\n",
    "\n",
    "        # Write preprocessed\n",
    "        super().save_file('preprocessed', 'pennsylvania')\n",
    "\n",
    "        self.df = self.df.select(\"date\", \"county\", \"state\", \"new_cases\").orderBy(\"date\", \"county\")\n",
    "\n",
    "        # Write final\n",
    "        super().save_file('final', 'pennsylvania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7145e2ef-04bf-4ada-af8c-298b4fc463ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Ohio(CleanAndStore):\n",
    "    \n",
    "    def __init__(self, load, load_type, save_path):\n",
    "        super().__init__(load, load_type, save_path)\n",
    "        self.wrangle()\n",
    "\n",
    "    def wrangle(self):\n",
    "\n",
    "        self.df = self.df.drop(\"Admission Date\", \"Date of Death\")\n",
    "\n",
    "        self.df = self.df.select(upper(col(\"County\")).alias(\"county\"),\n",
    "                                upper(col(\"Sex\")).alias(\"sex\"),\n",
    "                                col(\"Age Range\").alias(\"age\"),\n",
    "                                to_date(to_timestamp(col(\"Onset Date\"))).alias(\"date\"),\n",
    "                                col(\"Case Count\").cast(\"int\").alias(\"case\"),\n",
    "                                col(\"Hospitalized Count\").cast(\"int\").alias(\"hospitalized\"),\n",
    "                                col(\"Death Due To Illness Count - County Of Residence\").cast(\"int\").alias(\"death\")).filter(\"date IS NOT NULL\").distinct().orderBy(\"date\")\n",
    "\n",
    "        self.df = self.df.withColumn(\"state\", lit(\"OH\"))\n",
    "\n",
    "        self.df = self.df.filter(\"County != 'UNKNOWN'\")\n",
    "\n",
    "        # Write preprocessed\n",
    "        super().save_file('preprocessed', 'ohio')\n",
    "\n",
    "        self.df = self.df.select(\"date\", \"county\", \"state\", \"case\").groupBy(\"date\", \"county\", \"state\").agg(count(\"case\").cast(\"int\").alias(\"new_cases\")).orderBy(\"date\", \"county\")\n",
    "\n",
    "        # Write final\n",
    "        super().save_file('final', 'ohio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7cf00896-840c-44da-bef2-9ff77a832ecd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Georgia(CleanAndStore):\n",
    "\n",
    "    def __init__(self, load, load_type, save_path):\n",
    "        super().__init__(load, load_type, save_path)\n",
    "        self.wrangle()\n",
    "\n",
    "    def wrangle(self):\n",
    "\n",
    "        self.df = self.df.drop('OBJECTID', 'C_NEW_PERCT_CHG', 'D_NEW_PERCT_CHG', 'C_NEW_7D_MEAN', 'D_NEW_7D_MEAN', 'C_NEW_7D_PERCT_CHG', 'D_NEW_7D_PERCT_CHG', 'GlobalID')\n",
    "        \n",
    "        self.df = self.df.filter(\"COUNTY != 'UNKNOWN'\")\n",
    "\n",
    "        self.df = self.df.withColumn(\"date\", col(\"DATESTAMP\").cast(\"string\"))\n",
    "        self.df = self.df.drop(\"DATESTAMP\")\n",
    "\n",
    "        self.df = self.df.select(col(\"CNTY_FIPS\").cast(\"int\").alias(\"county_fips\"),\n",
    "                                upper(col(\"COUNTY\")).alias(\"county\"),\n",
    "                                to_date(from_unixtime(col(\"date\")[1:10])).alias(\"date\"),\n",
    "                                col(\"C_Age_0\").cast(\"int\").alias(\"cases_age_0\"),\n",
    "                                col(\"C_Age_0_4\").cast(\"int\").alias(\"cases_age_0_4\"),\n",
    "                                col(\"C_Age_15_24\").cast(\"int\").alias(\"cases_age_15_24\"),\n",
    "                                col(\"C_Age_20\").cast(\"int\").alias(\"cases_age_20\"),\n",
    "                                col(\"C_Age_25_34\").cast(\"int\").alias(\"cases_age_25_34\"),\n",
    "                                col(\"C_Age_35_44\").cast(\"int\").alias(\"cases_age_35_44\"),\n",
    "                                col(\"C_Age_45_54\").cast(\"int\").alias(\"cases_age_45_54\"),\n",
    "                                col(\"C_Age_55_64\").cast(\"int\").alias(\"cases_age_55_64\"),\n",
    "                                col(\"C_Age_5_14\").cast(\"int\").alias(\"cases_age_5_14\"),\n",
    "                                col(\"C_Age_65_74\").cast(\"int\").alias(\"cases_age_65_74\"),\n",
    "                                col(\"C_Age_75_84\").cast(\"int\").alias(\"cases_age_75_84\"),\n",
    "                                col(\"C_Age_85plus\").cast(\"int\").alias(\"cases_age_85plus\"),\n",
    "                                col(\"C_Age_Unkn\").cast(\"int\").alias(\"cases_age_unknown\"),\n",
    "                                col(\"C_Cum\").cast(\"int\").alias(\"cases_cumulative\"),\n",
    "                                col(\"C_EthUnk\").cast(\"int\").alias(\"cases_ethnicity_unknown\"),\n",
    "                                col(\"C_Female\").cast(\"int\").alias(\"cases_female\"),\n",
    "                                col(\"C_His\").cast(\"int\").alias(\"cases_hispanic\"),\n",
    "                                col(\"C_Male\").cast(\"int\").alias(\"cases_male\"),\n",
    "                                col(\"C_New\").cast(\"int\").alias(\"new_cases\"),\n",
    "                                col(\"C_NonHis\").cast(\"int\").alias(\"cases_nonhispanic\"),\n",
    "                                col(\"C_RaceAs\").cast(\"int\").alias(\"cases_asian\"),\n",
    "                                col(\"C_RaceBl\").cast(\"int\").alias(\"cases_black\"),\n",
    "                                col(\"C_RaceOth\").cast(\"int\").alias(\"cases_other\"),\n",
    "                                col(\"C_RaceUnk\").cast(\"int\").alias(\"cases_unknown\"),\n",
    "                                col(\"C_RaceWh\").cast(\"int\").alias(\"cases_white\"),\n",
    "                                col(\"C_SexUnkn\").cast(\"int\").alias(\"cases_sex_unknown\"),\n",
    "                                col(\"C_UCon_No\").cast(\"int\").alias(\"cases_condition_no\"),\n",
    "                                col(\"C_UCon_Unk\").cast(\"int\").alias(\"cases_condition_unknown\"),\n",
    "                                col(\"C_UCon_Yes\").cast(\"int\").alias(\"cases_condition_yes\"),\n",
    "                                col(\"D_Cum\").cast(\"int\").alias(\"deaths_cumulative\"),\n",
    "                                col(\"D_New\").cast(\"int\").alias(\"deaths_new\"),\n",
    "                                col(\"H_Cum\").cast(\"int\").alias(\"hospital_cumulative\"),\n",
    "                                col(\"H_New\").cast(\"int\").alias(\"hospital_new\")).distinct().orderBy(\"date\")\n",
    "\n",
    "        self.df = self.df.withColumn(\"state\", lit(\"GA\"))\n",
    "\n",
    "        self.df = self.df.filter(\"county != 'UNKNOWN'\")\n",
    "\n",
    "        # Write preprocessed\n",
    "        super().save_file('preprocessed', 'georgia')        \n",
    "\n",
    "        self.df = self.df.select(\"date\", \"county\", \"state\", \"new_cases\").orderBy(\"date\", \"county\")\n",
    "\n",
    "        # Write final\n",
    "        super().save_file('final', 'georgia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c0d85633-566a-4805-83af-7df377719fbe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Cases(CleanAndStore):\n",
    "\n",
    "    def __init__(self, load, load_type, save_path):\n",
    "        super().__init__(load, load_type, save_path)\n",
    "        self.columns = []\n",
    "        self.set_column_names()\n",
    "        self.wrangle()\n",
    "\n",
    "    def load_file(self, load, load_type):\n",
    "        \"\"\"\n",
    "        Load file from tmp storage\n",
    "        \"\"\"\n",
    "\n",
    "        container_client = ContainerClient.from_connection_string(conn_str = azure_conn_string, container_name = f\"{azure_container}\")\n",
    "        \n",
    "        # Download blob as StorageStreamDownloader object (stored in memory)\n",
    "        downloaded_blob = container_client.download_blob(f\"{load}\")\n",
    "\n",
    "        self.df = pd.read_csv(StringIO(downloaded_blob.content_as_text()))\n",
    "\n",
    "        return self.df   \n",
    "\n",
    "    def set_column_names(self):\n",
    "        \"\"\"\n",
    "        Transform column names so that the names can be referenced in each row\n",
    "        \"\"\"\n",
    "\n",
    "        for i in ['countyFIPS', 'County Name', 'State', 'StateFIPS']:\n",
    "            self.columns.append(i)\n",
    "\n",
    "        for column in self.df.columns[4:]:\n",
    "            self.columns.append(datetime.strptime(column, '%Y-%m-%d'))\n",
    "\n",
    "    def wrangle(self):\n",
    "        \"\"\"\n",
    "        Convert data frame sourced from Excel into JSON format\n",
    "        \"\"\"\n",
    "\n",
    "        counties = self.df[['countyFIPS', 'County Name', 'State', 'StateFIPS']].values\n",
    "\n",
    "        counties_converted = []\n",
    "\n",
    "        for i in range(len(counties)):\n",
    "            counties_converted.append(list(counties[i]))\n",
    "\n",
    "        for i in counties_converted:\n",
    "            i[1] = i[1].strip()\n",
    "            i[2] = i[2].strip()\n",
    "\n",
    "        records = []\n",
    "\n",
    "        for county in counties_converted:\n",
    "            for date in self.columns[4:]:\n",
    "                records.append([county[0], county[1], county[2], county[3], date])\n",
    "\n",
    "        county_cases = []\n",
    "\n",
    "        for row in self.df.itertuples(index=True):\n",
    "            county_cases.append(row[5:])\n",
    "\n",
    "        case_count = []\n",
    "\n",
    "        for county in county_cases:\n",
    "            for cases in county:\n",
    "                case_count.append(cases)\n",
    "\n",
    "        for i in range(len(records)):\n",
    "            records[i].append(case_count[i])\n",
    "\n",
    "        final_list = []\n",
    "\n",
    "        for row in records:\n",
    "            final_dict = {}\n",
    "            final_dict['countyFIPS'] = row[0]\n",
    "            final_dict['CountyName'] = row[1]\n",
    "            final_dict['State'] = row[2]\n",
    "            final_dict['StateFIPS'] = row[3]\n",
    "            final_dict['Date'] = row[4]\n",
    "            final_dict['Cases'] = row[5]\n",
    "            final_list.append(final_dict)\n",
    "\n",
    "        self.df = pd.DataFrame(final_list)\n",
    "\n",
    "        self.df = spark.createDataFrame(self.df)\n",
    "\n",
    "        self.df = self.df.select(col(\"countyFIPS\").cast(\"int\").alias(\"county_fips\"),\n",
    "                                upper(col(\"CountyName\")).alias(\"county\"),\n",
    "                                col(\"State\").alias(\"state\"),\n",
    "                                col(\"StateFIPS\").cast(\"int\").alias(\"state_fips\"),\n",
    "                                to_date(col(\"Date\")).alias(\"date\"),\n",
    "                                col(\"Cases\").cast(\"int\").alias(\"case_total\")).filter(\"state NOT IN ('FL', 'TX', 'NY', 'PA', 'IL', 'OH', 'GA')\").distinct()\n",
    "\n",
    "        # Write preprocessed\n",
    "        super().save_file('preprocessed', 'cases')  \n",
    "\n",
    "        windowSpec = Window.partitionBy(\"county\", \"state\").orderBy(\"date\")\n",
    "\n",
    "        self.df = self.df.withColumn(\"previous_day\", lag(\"case_total\", 1).over(windowSpec))\n",
    "\n",
    "        self.df = self.df.withColumn(\"new_cases\", (self.df.case_total - self.df.previous_day))    \n",
    "\n",
    "        self.df = self.df.select(\"date\", \"county\", \"state\", \"new_cases\")                  \n",
    "\n",
    "        # Write final\n",
    "        super().save_file('final', 'cases')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4696325d-2699-4c74-89ac-d2c90cae52c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Deaths(CleanAndStore):\n",
    "\n",
    "    def __init__(self, load, load_type, save_path):\n",
    "        super().__init__(load, load_type, save_path)\n",
    "        self.columns = []\n",
    "        self.set_column_names()\n",
    "        self.wrangle()\n",
    "\n",
    "    def load_file(self, load, load_type):\n",
    "        \"\"\"\n",
    "        Load file from tmp storage\n",
    "        \"\"\"\n",
    "        container_client = ContainerClient.from_connection_string(conn_str = azure_conn_string, container_name = f\"{azure_container}\")\n",
    "        \n",
    "        # Download blob as StorageStreamDownloader object (stored in memory)\n",
    "        downloaded_blob = container_client.download_blob(f\"{load}\")\n",
    "\n",
    "        self.df = pd.read_csv(StringIO(downloaded_blob.content_as_text()))\n",
    "\n",
    "        return self.df  \n",
    "\n",
    "    def set_column_names(self):\n",
    "        \"\"\"\n",
    "        Transform column names so that the names can be referenced in each row\n",
    "        \"\"\"\n",
    "\n",
    "        for i in ['countyFIPS', 'County Name', 'State', 'StateFIPS']:\n",
    "            self.columns.append(i)\n",
    "\n",
    "        for column in self.df.columns[4:]:\n",
    "            self.columns.append(datetime.strptime(column, '%Y-%m-%d'))\n",
    "\n",
    "    def wrangle(self):\n",
    "        \"\"\"\n",
    "        Convert data frame sourced from Excel into JSON format\n",
    "        \"\"\"\n",
    "\n",
    "        counties = self.df[['countyFIPS', 'County Name', 'State', 'StateFIPS']].values\n",
    "\n",
    "        counties_converted = []\n",
    "\n",
    "        for i in range(len(counties)):\n",
    "            counties_converted.append(list(counties[i]))\n",
    "\n",
    "        for i in counties_converted:\n",
    "            i[1] = i[1].strip()\n",
    "            i[2] = i[2].strip()\n",
    "\n",
    "        records = []\n",
    "\n",
    "        for county in counties_converted:\n",
    "            for date in self.columns[4:]:\n",
    "                records.append([county[0], county[1], county[2], county[3], date])\n",
    "\n",
    "        county_deaths = []\n",
    "\n",
    "        for row in self.df.itertuples(index=True):\n",
    "            county_deaths.append(row[5:])\n",
    "\n",
    "        death_count = []\n",
    "\n",
    "        for county in county_deaths:\n",
    "            for deaths in county:\n",
    "                death_count.append(deaths)\n",
    "\n",
    "        for i in range(len(records)):\n",
    "            records[i].append(death_count[i])\n",
    "\n",
    "        final_list = []\n",
    "\n",
    "        for row in records:\n",
    "            final_dict = {}\n",
    "            final_dict['countyFIPS'] = row[0]\n",
    "            final_dict['CountyName'] = row[1]\n",
    "            final_dict['State'] = row[2]\n",
    "            final_dict['StateFIPS'] = row[3]\n",
    "            final_dict['Date'] = row[4]\n",
    "            final_dict['Deaths'] = row[5]\n",
    "            final_list.append(final_dict)\n",
    "\n",
    "        self.df = pd.DataFrame(final_list)\n",
    "\n",
    "        self.df = spark.createDataFrame(self.df)\n",
    "\n",
    "        self.df = self.df.select(col(\"countyFIPS\").cast(\"int\").alias(\"county_fips\"),\n",
    "                                upper(col(\"CountyName\")).alias(\"county\"),\n",
    "                                col(\"State\").alias(\"state\"),\n",
    "                                col(\"StateFIPS\").cast(\"int\").alias(\"state_fips\"),\n",
    "                                to_date(col(\"Date\")).alias(\"date\"),\n",
    "                                col(\"Deaths\").cast(\"int\").alias(\"death_total\")).distinct()\n",
    "\n",
    "        # Write preprocessed\n",
    "        super().save_file('preprocessed', 'deaths')   \n",
    "\n",
    "        windowSpec = Window.partitionBy(\"county\", \"state\").orderBy(\"date\")\n",
    "\n",
    "        self.df = self.df.withColumn(\"previous_day\", lag(\"death_total\", 1).over(windowSpec))\n",
    "\n",
    "        self.df = self.df.withColumn(\"new_deaths\", (self.df.death_total - self.df.previous_day))         \n",
    "\n",
    "        self.df = self.df.select(\"date\", \"county\", \"state\", \"new_deaths\")\n",
    "\n",
    "        # Write final\n",
    "        super().save_file('final', 'deaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "021a63a6-9291-4444-a217-a2d8d8bf816a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Population(CleanAndStore):\n",
    "\n",
    "    def __init__(self, load, load_type, save_path):\n",
    "        super().__init__(load, load_type, save_path)\n",
    "\n",
    "        self.df = self.df.select(col(\"countyFIPS\").cast(\"int\").alias(\"county_fips\"),\n",
    "                                upper(col(\"County Name\")).alias(\"county\"),\n",
    "                                \"state\",\n",
    "                                col(\"population\").cast(\"int\").alias(\"population\")).distinct()\n",
    "\n",
    "        # Write final\n",
    "        super().save_file('final', 'population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "91c6bed6-48f5-4b3d-932f-2b19fc088f7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Stocks:\n",
    "\n",
    "    def __init__(self, load, save_path):\n",
    "        self.columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "        self.wrangle(load, save_path)\n",
    "\n",
    "    def wrangle(self, load, save_path):\n",
    "\n",
    "        client = AzureBlobClient(connection_string=azure_conn_string)\n",
    "        root = client.CloudPath(f\"az://{azure_container}/{load}\")\n",
    "        \n",
    "        for stock in root.glob('**/*.json'):\n",
    "\n",
    "            self.df = spark.read.json(f\"wasbs://{azure_container}@{azure_storage}.blob.core.windows.net/{str(stock)[24:]}\")\n",
    "            \n",
    "            df_filename = self.df.withColumn(\"filename\", input_file_name())\n",
    "            filename = df_filename.select(col(\"filename\")).first()\n",
    "            temp = filename[0][filename[0].rfind(\"/\") + 1: filename[0].rfind(\".\")]\n",
    "\n",
    "            self.df = self.df.select(to_date(\"date\").alias(\"date\"), \n",
    "                                    col(\"open\").cast(\"float\").alias(\"open\"),\n",
    "                                    col(\"high\").cast(\"float\").alias(\"high\"),\n",
    "                                    col(\"low\").cast(\"float\").alias(\"low\"),\n",
    "                                    col(\"close\").cast(\"float\").alias(\"close\"),\n",
    "                                    col(\"volume\").cast(\"float\").alias(\"volume\")).orderBy(\"date\")\n",
    "\n",
    "            # Write final            \n",
    "            self.df.write.mode(\"overwrite\").parquet(f'wasbs://{azure_container}@{azure_storage}.blob.core.windows.net/{save_path}/{stock.stem}/final/{temp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ce4d7c79-22ed-416a-b5e5-7a71123aee3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Indicator(CleanAndStore):\n",
    "\n",
    "    def __init__(self, load, load_type, save_path, indicator):\n",
    "        super().__init__(load, load_type, save_path)\n",
    "        self.indicator = indicator\n",
    "        self.wrangle()\n",
    "\n",
    "    def load_file(self, load, load_type):\n",
    "        \"\"\"\n",
    "        Load file from tmp storage\n",
    "        \"\"\"        \n",
    "        self.df = spark.read.format(load_type).option(\"header\", True).load(f\"wasbs://{azure_container}@{azure_storage}.blob.core.windows.net/{load}\")\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def wrangle(self):\n",
    "\n",
    "        self.df = self.df.select(to_date(\"date\").alias(\"date\"), col(self.indicator).cast(\"float\").alias(self.indicator)).orderBy(\"date\")\n",
    "        \n",
    "        # Write final\n",
    "        super().save_file('final', self.indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "605e8f34-9f5f-4429-80a3-a5198a50fdd2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Texas(f'{tmp_county_path}/texas.xlsx', county_path)\n",
    "Florida(f'{tmp_county_path}/florida2020.json', 'json', county_path)\n",
    "Florida(f'{tmp_county_path}/florida2021.json', 'json', county_path)\n",
    "NewYork(f'{tmp_county_path}/new-york.json', 'json', county_path)\n",
    "Pennsylvania(f'{tmp_county_path}/pennsylvania.json', 'json', county_path)\n",
    "Ohio(f'{tmp_county_path}/ohio.csv', 'csv', county_path)\n",
    "Georgia(f'{tmp_county_path}/georgia.json', 'json', county_path)\n",
    "Cases(f'{tmp_county_path}/cases.csv', 'csv', county_path)\n",
    "Deaths(f'{tmp_county_path}/deaths.csv', 'csv', county_path)\n",
    "Population(f'{tmp_county_path}/population.csv', 'csv', county_path)\n",
    "Stocks(tmp_stock_path, stock_path)\n",
    "Indicator(f'{tmp_indicator_path}/unemployment.json', 'json', indicator_path, 'unemployment')\n",
    "Indicator(f'{tmp_indicator_path}/inflation.json', 'json', indicator_path, 'inflation')\n",
    "Indicator(f'{tmp_indicator_path}/sentiment.json', 'json', indicator_path, 'sentiment')\n",
    "Indicator(f'{tmp_indicator_path}/mortgage.json', 'json', indicator_path, 'mortgage')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "covid-stock-clean",
   "notebookOrigID": 4395203700818834,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
